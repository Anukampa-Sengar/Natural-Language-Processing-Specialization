NLP Specialization is a 4 course series covering machine learning basics and state-of-the-art deep learning techniques, as mentioned below, needed to build cutting-edge NLP systems:

• Logistic regression, naïve Bayes, and word vectors to implement sentiment analysis, complete analogies, translate words, and use of locality-sensitive hashing to approximate nearest neighbors.

• Dynamic programming, hidden Markov models, and word embeddings to autocorrect misspelled words, autocomplete partial sentences, and identify part-of-speech tags for words.

• Dense and recurrent neural networks, LSTMs, GRUs, and Siamese networks in TensorFlow to perform advanced sentiment analysis, text generation, named entity recognition, and to identify duplicate questions. 

• Encoder-decoder, causal, and self-attention to perform advanced machine translation of complete sentences, text summarization, and question-answering. Learn models like T5, BERT, and more with Hugging Face Transformers!


As AI advances, proficiency in NLP techniques remains essential for analyzing speech and language, extracting insights, and developing text-based applications. By the end of this specialization, it will be possible to design NLP applications that perform question-answering and sentiment analysis, create tools to translate languages, and summarize text.


**Course 1 - Natural Language Processing with Classification and Vector Spaces**  
_Learning included:_  
Use logistic regression, naïve Bayes, and word vectors to implement sentiment analysis, complete analogies & translate words.  
_Skills to be acquired:_  
Machine Translation, Locality-Sensitive Hashing, Sentiment Analysis, Word Embeddings, Vector Space Models

**Course 2 - Natural Language Processing with Probabilistic Models**  
_Learning included:_  
Use dynamic programming, hidden Markov models, and word embeddings to implement autocorrect, autocomplete & identify part-of-speech tags for words.  
_Skills to be acquied:_  
N-gram Language Models, Autocorrect, Parts-of-Speech Tagging, Word2vec

**Course 3 - Natural Language Processing with Sequence Models**  
_Learning included:_  
Use recurrent neural networks, LSTMs, GRUs & Siamese networks in TensorFlow for sentiment analysis, text generation & named entity recognition.  
_Skills to be acquied:_  
Word Embedding, Siamese Networks, Sentiment with Neural Nets, Natural Language Generation, Named-Entity Recognition

**Course 4 - Natural Language Processing with Attention Models**  
_Learning included:_  
Use encoder-decoder, causal, & self-attention to machine translate complete sentences, summarize text, and answer questions.  
_Skills to be acquied:_  
T5+BERT Models, Neural Machine Translation, Question Answering, Attention Models, Text Summarization
